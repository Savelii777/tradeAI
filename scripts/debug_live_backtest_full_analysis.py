#!/usr/bin/env python3
"""
–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –ª–∞–π–≤–æ–º –∏ –±–µ–∫—Ç–µ—Å—Ç–æ–º.
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç:
1. –ó–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö (—Å–∫–æ–ª—å–∫–æ —Å–≤–µ—á–µ–π, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏)
2. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ–∏—á–µ–π (OBV, –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
4. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤
"""

import sys
import json
from pathlib import Path
from datetime import datetime, timedelta, timezone
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import joblib
import ccxt
from loguru import logger

sys.path.insert(0, str(Path(__file__).parent.parent))
from train_mtf import MTFFeatureEngine

# ============================================================
# CONFIG
# ============================================================
MODEL_DIR = Path("models/v8_improved")
PAIRS_FILE = Path("config/pairs_list.json")
DATA_DIR = Path("data/candles")
LOOKBACK = 1500  # –ö–∞–∫ –≤ –ª–∞–π–≤–µ

# –ü–æ—Ä–æ–≥–∏ –∫–∞–∫ –≤ –ª–∞–π–≤–µ
MIN_CONF = 0.50
MIN_TIMING = 0.8
MIN_STRENGTH = 1.4

# ============================================================
# UTILS
# ============================================================
def add_volume_features(df):
    """–¢–æ—á–Ω–æ –∫–∞–∫ –≤ –ª–∞–π–≤–µ –∏ –±–µ–∫—Ç–µ—Å—Ç–µ"""
    df = df.copy()
    df['vol_sma_20'] = df['volume'].rolling(20).mean()
    df['vol_ratio'] = df['volume'] / df['vol_sma_20']
    df['vol_zscore'] = (df['volume'] - df['vol_sma_20']) / df['volume'].rolling(20).std()
    
    df['price_change'] = df['close'].diff()
    df['obv'] = np.where(df['price_change'] > 0, df['volume'], -df['volume']).cumsum()
    df['obv_sma'] = pd.Series(df['obv']).rolling(20).mean()
    
    df['vwap'] = (df['close'] * df['volume']).rolling(20).sum() / df['volume'].rolling(20).sum()
    df['price_vs_vwap'] = df['close'] / df['vwap'] - 1
    
    df['vol_momentum'] = df['volume'].pct_change(5)
    
    return df

def calculate_atr(df, period=14):
    high = df['high']
    low = df['low']
    close = df['close']
    tr = pd.concat([high - low, abs(high - close.shift()), abs(low - close.shift())], axis=1).max(axis=1)
    return tr.ewm(span=period, adjust=False).mean()

def prepare_features(data, mtf_fe):
    """–¢–æ—á–Ω–æ –∫–∞–∫ –≤ –ª–∞–π–≤–µ"""
    m1 = data['1m']
    m5 = data['5m']
    m15 = data['15m']
    
    if len(m1) < 50 or len(m5) < 50 or len(m15) < 50:
        return pd.DataFrame()
    
    # Ensure DatetimeIndex
    for df in [m1, m5, m15]:
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index, utc=True)
        df.sort_index(inplace=True)
    
    try:
        ft = mtf_fe.align_timeframes(m1, m5, m15)
        if len(ft) == 0:
            return pd.DataFrame()
        
        ft = ft.join(m5[['open', 'high', 'low', 'close', 'volume']])
        ft = add_volume_features(ft)
        ft['atr'] = calculate_atr(ft)
        
        # Fill NaN
        critical_cols = ['close', 'atr']
        ft = ft.dropna(subset=critical_cols)
        ft = ft.ffill().bfill()
        
        if ft.isna().any().any():
            ft = ft.fillna(0)
        
        return ft
    except Exception as e:
        logger.error(f"Error preparing features: {e}")
        return pd.DataFrame()

# ============================================================
# DATA LOADING
# ============================================================
def load_backtest_data(pair, target_date):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV (–∫–∞–∫ –≤ –±–µ–∫—Ç–µ—Å—Ç–µ)"""
    pair_name = pair.replace('/', '_').replace(':', '_')
    
    data = {}
    for tf in ['1m', '5m', '15m']:
        file_path = DATA_DIR / f"{pair_name}_{tf}.csv"
        if not file_path.exists():
            return None
        
        df = pd.read_csv(file_path, parse_dates=['timestamp'], index_col='timestamp')
        
        # –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –∏–Ω–¥–µ–∫—Å –∏–º–µ–µ—Ç timezone (–µ—Å–ª–∏ –Ω–µ—Ç - –¥–æ–±–∞–≤–∏—Ç—å UTC)
        if df.index.tz is None:
            df.index = df.index.tz_localize('UTC')
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–æ target_date (–∫–∞–∫ –≤ –±–µ–∫—Ç–µ—Å—Ç–µ - –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–æ —ç—Ç–æ–π –¥–∞—Ç—ã)
        df = df[df.index <= target_date]
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ LOOKBACK —Å–≤–µ—á–µ–π (–∫–∞–∫ –≤ –ª–∞–π–≤–µ)
        if len(df) > LOOKBACK:
            df = df.tail(LOOKBACK)
        
        data[tf] = df
    
    return data

def fetch_live_data(pair, binance):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API (–∫–∞–∫ –≤ –ª–∞–π–≤–µ)"""
    data = {}
    for tf in ['1m', '5m', '15m']:
        try:
            candles = binance.fetch_ohlcv(pair, tf, limit=LOOKBACK)
            if not candles or len(candles) < 50:
                return None
            
            df = pd.DataFrame(candles, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
            df.set_index('timestamp', inplace=True)
            data[tf] = df
        except Exception as e:
            logger.error(f"Error fetching {pair} {tf}: {e}")
            return None
    
    return data

# ============================================================
# ANALYSIS
# ============================================================
def compare_data_loading(pair, target_date):
    """–°—Ä–∞–≤–Ω–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö"""
    logger.info(f"\n{'='*70}")
    logger.info(f"üìä –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–•: {pair}")
    logger.info(f"{'='*70}")
    
    # Backtest data
    backtest_data = load_backtest_data(pair, target_date)
    if backtest_data is None:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–µ–∫—Ç–µ—Å—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è {pair}")
        return None
    
    # Live data
    binance = ccxt.binance({
        'timeout': 10000,
        'enableRateLimit': True,
        'options': {'defaultType': 'future'}
    })
    live_data = fetch_live_data(pair, binance)
    if live_data is None:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–∞–π–≤ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {pair}")
        return None
    
    comparison = {}
    
    for tf in ['1m', '5m', '15m']:
        bt_df = backtest_data[tf]
        lv_df = live_data[tf]
        
        logger.info(f"\n{tf}:")
        logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç: {len(bt_df)} —Å–≤–µ—á–µ–π | –ü–µ—Ä–≤–∞—è: {bt_df.index[0]} | –ü–æ—Å–ª–µ–¥–Ω—è—è: {bt_df.index[-1]}")
        logger.info(f"  –õ–∞–π–≤:    {len(lv_df)} —Å–≤–µ—á–µ–π | –ü–µ—Ä–≤–∞—è: {lv_df.index[0]} | –ü–æ—Å–ª–µ–¥–Ω—è—è: {lv_df.index[-1]}")
        
        # –°—Ä–∞–≤–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–≤–µ—á–µ–π
        n_compare = min(10, len(bt_df), len(lv_df))
        bt_last = bt_df.tail(n_compare)
        lv_last = lv_df.tail(n_compare)
        
        # –ù–∞–π—Ç–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        common_times = bt_last.index.intersection(lv_last.index)
        
        if len(common_times) > 0:
            bt_common = bt_last.loc[common_times]
            lv_common = lv_last.loc[common_times]
            
            close_diff = (bt_common['close'] - lv_common['close']).abs()
            volume_diff = (bt_common['volume'] - lv_common['volume']).abs()
            
            logger.info(f"  ‚úÖ –û–±—â–∏—Ö —Å–≤–µ—á–µ–π: {len(common_times)}")
            logger.info(f"  –ú–∞–∫—Å —Ä–∞–∑–Ω–∏—Ü–∞ close: {close_diff.max():.6f} ({close_diff.max() / bt_common['close'].mean() * 100:.4f}%)")
            logger.info(f"  –ú–∞–∫—Å —Ä–∞–∑–Ω–∏—Ü–∞ volume: {volume_diff.max():.2f} ({volume_diff.max() / bt_common['volume'].mean() * 100:.2f}%)")
        else:
            logger.warning(f"  ‚ö†Ô∏è –ù–µ—Ç –æ–±—â–∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫!")
        
        comparison[tf] = {
            'backtest_count': len(bt_df),
            'live_count': len(lv_df),
            'backtest_first': bt_df.index[0],
            'backtest_last': bt_df.index[-1],
            'live_first': lv_df.index[0],
            'live_last': lv_df.index[-1],
            'common_times': len(common_times) if len(common_times) > 0 else 0
        }
    
    return {
        'pair': pair,
        'target_date': target_date,
        'data_comparison': comparison,
        'backtest_data': backtest_data,
        'live_data': live_data
    }

def compare_features(comparison_result):
    """–°—Ä–∞–≤–Ω–∏—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ–∏—á–µ–π"""
    logger.info(f"\n{'='*70}")
    logger.info(f"üîß –°–†–ê–í–ù–ï–ù–ò–ï –§–ò–ß–ï–ô: {comparison_result['pair']}")
    logger.info(f"{'='*70}")
    
    mtf_fe = MTFFeatureEngine()
    
    # Backtest features
    bt_features = prepare_features(comparison_result['backtest_data'], mtf_fe)
    if bt_features.empty:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –±–µ–∫—Ç–µ—Å—Ç —Ñ–∏—á–∏")
        return None
    
    # Live features
    lv_features = prepare_features(comparison_result['live_data'], mtf_fe)
    if lv_features.empty:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ª–∞–π–≤ —Ñ–∏—á–∏")
        return None
    
    logger.info(f"\n–ë–µ–∫—Ç–µ—Å—Ç —Ñ–∏—á–∏: {len(bt_features)} —Å—Ç—Ä–æ–∫, {len(bt_features.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    logger.info(f"–õ–∞–π–≤ —Ñ–∏—á–∏:    {len(lv_features)} —Å—Ç—Ä–æ–∫, {len(lv_features.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    
    # –°—Ä–∞–≤–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–≤–µ—á—É (–∫–∞–∫ –≤ –ª–∞–π–≤–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è iloc[-2])
    bt_last = bt_features.iloc[[-2]] if len(bt_features) >= 2 else bt_features.iloc[[-1]]
    lv_last = lv_features.iloc[[-2]] if len(lv_features) >= 2 else lv_features.iloc[[-1]]
    
    logger.info(f"\n–ë–µ–∫—Ç–µ—Å—Ç –ø–æ—Å–ª–µ–¥–Ω—è—è —Å–≤–µ—á–∞: {bt_last.index[0]}")
    logger.info(f"–õ–∞–π–≤ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å–≤–µ—á–∞:    {lv_last.index[0]}")
    
    # –°—Ä–∞–≤–Ω–∏—Ç—å –æ–±—â–∏–µ —Ñ–∏—á–∏
    common_features = set(bt_features.columns) & set(lv_features.columns)
    logger.info(f"\n–û–±—â–∏—Ö —Ñ–∏—á–µ–π: {len(common_features)}")
    
    # –°—Ä–∞–≤–Ω–∏—Ç—å OBV (–∫—Ä–∏—Ç–∏—á–Ω–æ!)
    if 'obv' in common_features:
        bt_obv = bt_features['obv'].iloc[-10:].values
        lv_obv = lv_features['obv'].iloc[-10:].values
        
        logger.info(f"\nüìä OBV —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10):")
        logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç: {bt_obv}")
        logger.info(f"  –õ–∞–π–≤:    {lv_obv}")
        logger.info(f"  –†–∞–∑–Ω–∏—Ü–∞: {np.abs(bt_obv - lv_obv[:len(bt_obv)])}")
    
    # –°—Ä–∞–≤–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–∏—á–µ–π –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–∏
    feature_diffs = {}
    for feat in common_features:
        if feat in bt_last.columns and feat in lv_last.columns:
            bt_val = bt_last[feat].iloc[0]
            lv_val = lv_last[feat].iloc[0]
            
            if pd.notna(bt_val) and pd.notna(lv_val):
                if isinstance(bt_val, (int, float)) and isinstance(lv_val, (int, float)):
                    diff = abs(bt_val - lv_val)
                    if diff > 1e-6:  # –ó–Ω–∞—á–∏–º–∞—è —Ä–∞–∑–Ω–∏—Ü–∞
                        feature_diffs[feat] = {
                            'backtest': bt_val,
                            'live': lv_val,
                            'diff': diff,
                            'diff_pct': (diff / abs(bt_val) * 100) if bt_val != 0 else 0
                        }
    
    if feature_diffs:
        logger.info(f"\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(feature_diffs)} —Ñ–∏—á–µ–π —Å —Ä–∞–∑–ª–∏—á–∏—è–º–∏:")
        for feat, diff_info in sorted(feature_diffs.items(), key=lambda x: x[1]['diff'], reverse=True)[:20]:
            logger.info(f"  {feat}: BT={diff_info['backtest']:.6f}, LV={diff_info['live']:.6f}, "
                       f"Diff={diff_info['diff']:.6f} ({diff_info['diff_pct']:.2f}%)")
    
    return {
        'backtest_features': bt_features,
        'live_features': lv_features,
        'backtest_last': bt_last,
        'live_last': lv_last,
        'feature_diffs': feature_diffs
    }

def compare_predictions(comparison_result, feature_comparison):
    """–°—Ä–∞–≤–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    logger.info(f"\n{'='*70}")
    logger.info(f"ü§ñ –°–†–ê–í–ù–ï–ù–ò–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô: {comparison_result['pair']}")
    logger.info(f"{'='*70}")
    
    # Load models
    models = {
        'direction': joblib.load(MODEL_DIR / 'direction_model.joblib'),
        'timing': joblib.load(MODEL_DIR / 'timing_model.joblib'),
        'strength': joblib.load(MODEL_DIR / 'strength_model.joblib'),
        'features': joblib.load(MODEL_DIR / 'feature_names.joblib')
    }
    
    bt_features = feature_comparison['backtest_features']
    lv_features = feature_comparison['live_features']
    
    bt_last = feature_comparison['backtest_last']
    lv_last = feature_comparison['live_last']
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö —Ñ–∏—á–µ–π
    missing_bt = [f for f in models['features'] if f not in bt_last.columns]
    missing_lv = [f for f in models['features'] if f not in lv_last.columns]
    
    if missing_bt:
        logger.warning(f"‚ö†Ô∏è –ë–µ–∫—Ç–µ—Å—Ç: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏—á–∏: {missing_bt[:10]}")
    if missing_lv:
        logger.warning(f"‚ö†Ô∏è –õ–∞–π–≤: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏—á–∏: {missing_lv[:10]}")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –±–µ–∫—Ç–µ—Å—Ç–∞
    bt_X = bt_last[models['features']].values
    if pd.isna(bt_X).any():
        logger.warning("‚ö†Ô∏è –ë–µ–∫—Ç–µ—Å—Ç: NaN –≤ —Ñ–∏—á–∞—Ö, –∑–∞–ø–æ–ª–Ω—è—é –Ω—É–ª—è–º–∏")
        bt_X = np.nan_to_num(bt_X)
    
    bt_dir_proba = models['direction'].predict_proba(bt_X)
    bt_dir_conf = float(np.max(bt_dir_proba))
    bt_dir_pred = int(np.argmax(bt_dir_proba))
    bt_timing = float(models['timing'].predict(bt_X)[0])
    bt_strength = float(models['strength'].predict(bt_X)[0])
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –ª–∞–π–≤–∞
    lv_X = lv_last[models['features']].values
    if pd.isna(lv_X).any():
        logger.warning("‚ö†Ô∏è –õ–∞–π–≤: NaN –≤ —Ñ–∏—á–∞—Ö, –∑–∞–ø–æ–ª–Ω—è—é –Ω—É–ª—è–º–∏")
        lv_X = np.nan_to_num(lv_X)
    
    lv_dir_proba = models['direction'].predict_proba(lv_X)
    lv_dir_conf = float(np.max(lv_dir_proba))
    lv_dir_pred = int(np.argmax(lv_dir_proba))
    lv_timing = float(models['timing'].predict(lv_X)[0])
    lv_strength = float(models['strength'].predict(lv_X)[0])
    
    direction_map = {0: 'SHORT', 1: 'SIDEWAYS', 2: 'LONG'}
    
    logger.info(f"\nüìä –ë–ï–ö–¢–ï–°–¢ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø:")
    logger.info(f"  Direction: {direction_map[bt_dir_pred]} (conf: {bt_dir_conf:.3f})")
    logger.info(f"  Timing: {bt_timing:.3f} ATR")
    logger.info(f"  Strength: {bt_strength:.2f}")
    
    logger.info(f"\nüìä –õ–ê–ô–í –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø:")
    logger.info(f"  Direction: {direction_map[lv_dir_pred]} (conf: {lv_dir_conf:.3f})")
    logger.info(f"  Timing: {lv_timing:.3f} ATR")
    logger.info(f"  Strength: {lv_strength:.2f}")
    
    logger.info(f"\nüìä –†–ê–ó–ù–ò–¶–´:")
    logger.info(f"  Direction: {'‚úÖ' if bt_dir_pred == lv_dir_pred else '‚ùå'} "
               f"({direction_map[bt_dir_pred]} vs {direction_map[lv_dir_pred]})")
    logger.info(f"  Conf: {abs(bt_dir_conf - lv_dir_conf):.4f}")
    logger.info(f"  Timing: {abs(bt_timing - lv_timing):.4f}")
    logger.info(f"  Strength: {abs(bt_strength - lv_strength):.4f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    bt_passes = (bt_dir_pred != 1 and 
                 bt_dir_conf >= MIN_CONF and 
                 bt_timing >= MIN_TIMING and 
                 bt_strength >= MIN_STRENGTH)
    
    lv_passes = (lv_dir_pred != 1 and 
                 lv_dir_conf >= MIN_CONF and 
                 lv_timing >= MIN_TIMING and 
                 lv_strength >= MIN_STRENGTH)
    
    logger.info(f"\nüéØ –§–ò–õ–¨–¢–†–´:")
    logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç: {'‚úÖ' if bt_passes else '‚ùå'}")
    logger.info(f"  –õ–∞–π–≤ –ø—Ä–æ—Ö–æ–¥–∏—Ç:    {'‚úÖ' if lv_passes else '‚ùå'}")
    
    if not bt_passes:
        reasons = []
        if bt_dir_pred == 1:
            reasons.append("SIDEWAYS")
        if bt_dir_conf < MIN_CONF:
            reasons.append(f"Conf({bt_dir_conf:.2f}<{MIN_CONF})")
        if bt_timing < MIN_TIMING:
            reasons.append(f"Timing({bt_timing:.2f}<{MIN_TIMING})")
        if bt_strength < MIN_STRENGTH:
            reasons.append(f"Strength({bt_strength:.2f}<{MIN_STRENGTH})")
        logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è: {', '.join(reasons)}")
    
    if not lv_passes:
        reasons = []
        if lv_dir_pred == 1:
            reasons.append("SIDEWAYS")
        if lv_dir_conf < MIN_CONF:
            reasons.append(f"Conf({lv_dir_conf:.2f}<{MIN_CONF})")
        if lv_timing < MIN_TIMING:
            reasons.append(f"Timing({lv_timing:.2f}<{MIN_TIMING})")
        if lv_strength < MIN_STRENGTH:
            reasons.append(f"Strength({lv_strength:.2f}<{MIN_STRENGTH})")
        logger.info(f"  –õ–∞–π–≤ –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è: {', '.join(reasons)}")
    
    return {
        'backtest': {
            'direction': bt_dir_pred,
            'direction_str': direction_map[bt_dir_pred],
            'conf': bt_dir_conf,
            'timing': bt_timing,
            'strength': bt_strength,
            'passes': bt_passes
        },
        'live': {
            'direction': lv_dir_pred,
            'direction_str': direction_map[lv_dir_pred],
            'conf': lv_dir_conf,
            'timing': lv_timing,
            'strength': lv_strength,
            'passes': lv_passes
        }
    }

# ============================================================
# MAIN
# ============================================================
def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--pair", type=str, default="BTC/USDT:USDT", help="Pair to analyze")
    parser.add_argument("--date", type=str, default=None, help="Target date (YYYY-MM-DD), defaults to yesterday")
    args = parser.parse_args()
    
    # Default to yesterday
    if args.date:
        target_date = datetime.strptime(args.date, '%Y-%m-%d').replace(tzinfo=timezone.utc)
    else:
        target_date = (datetime.now(timezone.utc) - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
    
    logger.info("="*70)
    logger.info("–ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ê–ó–õ–ò–ß–ò–ô –õ–ê–ô–í vs –ë–ï–ö–¢–ï–°–¢")
    logger.info("="*70)
    logger.info(f"–ü–∞—Ä–∞: {args.pair}")
    logger.info(f"–¶–µ–ª–µ–≤–∞—è –¥–∞—Ç–∞: {target_date}")
    logger.info("="*70)
    
    # 1. –°—Ä–∞–≤–Ω–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö
    comparison = compare_data_loading(args.pair, target_date)
    if comparison is None:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return
    
    # 2. –°—Ä–∞–≤–Ω–∏—Ç—å —Ñ–∏—á–∏
    feature_comp = compare_features(comparison)
    if feature_comp is None:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ä–∞–≤–Ω–∏—Ç—å —Ñ–∏—á–∏")
        return
    
    # 3. –°—Ä–∞–≤–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    pred_comp = compare_predictions(comparison, feature_comp)
    
    # 4. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    logger.info(f"\n{'='*70}")
    logger.info("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    logger.info(f"{'='*70}")
    
    logger.info(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã:")
    logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç: {comparison['data_comparison']['5m']['backtest_count']} —Å–≤–µ—á–µ–π 5m")
    logger.info(f"  –õ–∞–π–≤:    {comparison['data_comparison']['5m']['live_count']} —Å–≤–µ—á–µ–π 5m")
    
    logger.info(f"\n‚úÖ –§–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã:")
    logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç: {len(feature_comp['backtest_features'])} —Å—Ç—Ä–æ–∫")
    logger.info(f"  –õ–∞–π–≤:    {len(feature_comp['live_features'])} —Å—Ç—Ä–æ–∫")
    logger.info(f"  –†–∞–∑–ª–∏—á–∏–π –≤ —Ñ–∏—á–∞—Ö: {len(feature_comp['feature_diffs'])}")
    
    logger.info(f"\n‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç: {pred_comp['backtest']['direction_str']} "
               f"(conf={pred_comp['backtest']['conf']:.3f}, "
               f"timing={pred_comp['backtest']['timing']:.2f}, "
               f"strength={pred_comp['backtest']['strength']:.2f})")
    logger.info(f"  –õ–∞–π–≤:    {pred_comp['live']['direction_str']} "
               f"(conf={pred_comp['live']['conf']:.3f}, "
               f"timing={pred_comp['live']['timing']:.2f}, "
               f"strength={pred_comp['live']['strength']:.2f})")
    
    logger.info(f"\n‚úÖ –°–∏–≥–Ω–∞–ª:")
    logger.info(f"  –ë–µ–∫—Ç–µ—Å—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç —Ñ–∏–ª—å—Ç—Ä—ã: {'‚úÖ –î–ê' if pred_comp['backtest']['passes'] else '‚ùå –ù–ï–¢'}")
    logger.info(f"  –õ–∞–π–≤ –ø—Ä–æ—Ö–æ–¥–∏—Ç —Ñ–∏–ª—å—Ç—Ä—ã:    {'‚úÖ –î–ê' if pred_comp['live']['passes'] else '‚ùå –ù–ï–¢'}")
    
    if pred_comp['backtest']['passes'] and not pred_comp['live']['passes']:
        logger.error("\n‚ùå –ü–†–û–ë–õ–ï–ú–ê: –ë–µ–∫—Ç–µ—Å—Ç –¥–∞–µ—Ç —Å–∏–≥–Ω–∞–ª, –∞ –ª–∞–π–≤ - –Ω–µ—Ç!")
        logger.error("   –≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç –ø–æ—á–µ–º—É –≤ –ª–∞–π–≤–µ –Ω–µ—Ç —Å–¥–µ–ª–æ–∫.")
    elif not pred_comp['backtest']['passes'] and pred_comp['live']['passes']:
        logger.warning("\n‚ö†Ô∏è  –õ–∞–π–≤ –¥–∞–µ—Ç —Å–∏–≥–Ω–∞–ª, –∞ –±–µ–∫—Ç–µ—Å—Ç - –Ω–µ—Ç (–Ω–µ–æ–±—ã—á–Ω–æ)")
    elif pred_comp['backtest']['passes'] and pred_comp['live']['passes']:
        logger.info("\n‚úÖ –û–±–∞ –¥–∞—é—Ç —Å–∏–≥–Ω–∞–ª - –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    else:
        logger.info("\n‚ÑπÔ∏è  –û–±–∞ –Ω–µ –¥–∞—é—Ç —Å–∏–≥–Ω–∞–ª - –Ω–µ—Ç —Å–¥–µ–ª–æ–∫ –≤ –æ–±–æ–∏—Ö —Å–ª—É—á–∞—è—Ö")

if __name__ == '__main__':
    main()

