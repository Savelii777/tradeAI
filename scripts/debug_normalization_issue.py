#!/usr/bin/env python3
"""
–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú–´ –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò

–ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–∏–ø–æ—Ç–µ–∑—É: rolling –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞—ë—Ç —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
—Ñ–∏—á–µ–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

–¢–µ—Å—Ç:
1. –ë–µ—Ä—ë–º CSV –¥–∞–Ω–Ω—ã–µ –∑–∞ –º–µ—Å—è—Ü
2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏—á–∏ –¥–ª—è –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –≤ –±—ç–∫—Ç–µ—Å—Ç–µ)
3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏—á–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 1500 —Å–≤–µ—á–µ–π (–∫–∞–∫ –≤ –ª–∞–π–≤–µ)
4. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–∏—á–µ–π –¥–ª—è –û–î–ù–û–ì–û –ò –¢–û–ì–û –ñ–ï –í–†–ï–ú–ï–ù–ò
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timezone

sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent))

from train_mtf import MTFFeatureEngine, load_mtf_data

DATA_DIR = Path(__file__).parent.parent / "data" / "candles"


def add_volume_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df['vol_sma_20'] = df['volume'].rolling(20).mean()
    df['vol_ratio'] = df['volume'] / df['vol_sma_20']
    df['vol_zscore'] = (df['volume'] - df['vol_sma_20']) / df['volume'].rolling(20).std()
    df['vwap'] = (df['close'] * df['volume']).rolling(20).sum() / df['volume'].rolling(20).sum()
    df['price_vs_vwap'] = df['close'] / df['vwap'] - 1
    df['vol_momentum'] = df['volume'].pct_change(5)
    return df


def test_normalization_impact():
    """
    –¢–µ—Å—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É —Ñ–∏—á–µ–π –ø—Ä–∏ —Ä–∞–∑–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    print("=" * 70)
    print("–¢–ï–°–¢ –í–õ–ò–Ø–ù–ò–Ø –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–µ CSV –¥–∞–Ω–Ω—ã–µ
    pair = "BTC/USDT:USDT"
    pair_name = pair.replace('/', '_').replace(':', '_')
    
    m1_full = pd.read_csv(DATA_DIR / f"{pair_name}_1m.csv", parse_dates=['timestamp'], index_col='timestamp')
    m5_full = pd.read_csv(DATA_DIR / f"{pair_name}_5m.csv", parse_dates=['timestamp'], index_col='timestamp')
    m15_full = pd.read_csv(DATA_DIR / f"{pair_name}_15m.csv", parse_dates=['timestamp'], index_col='timestamp')
    
    print(f"\nüìä –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"   M1: {len(m1_full)} —Å–≤–µ—á–µ–π ({m1_full.index[0]} ‚Üí {m1_full.index[-1]})")
    print(f"   M5: {len(m5_full)} —Å–≤–µ—á–µ–π ({m5_full.index[0]} ‚Üí {m5_full.index[-1]})")
    print(f"   M15: {len(m15_full)} —Å–≤–µ—á–µ–π ({m15_full.index[0]} ‚Üí {m15_full.index[-1]})")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã "–ª–∞–π–≤–∞" - –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–≤–µ—á–µ–π
    LIVE_CANDLES_M5 = 1500
    LIVE_CANDLES_M1 = 1500
    LIVE_CANDLES_M15 = 500
    
    # –†–µ–∂–∏–º "–ª–∞–π–≤" - —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–≤–µ—á–∏
    m1_live = m1_full.tail(LIVE_CANDLES_M1)
    m5_live = m5_full.tail(LIVE_CANDLES_M5)
    m15_live = m15_full.tail(LIVE_CANDLES_M15)
    
    print(f"\nüìä 'Live' –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–≤–µ—á–∏):")
    print(f"   M1: {len(m1_live)} —Å–≤–µ—á–µ–π ({m1_live.index[0]} ‚Üí {m1_live.index[-1]})")
    print(f"   M5: {len(m5_live)} —Å–≤–µ—á–µ–π ({m5_live.index[0]} ‚Üí {m5_live.index[-1]})")
    print(f"   M15: {len(m15_live)} —Å–≤–µ—á–µ–π ({m15_live.index[0]} ‚Üí {m15_live.index[-1]})")
    
    # –¢–æ—á–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è - –ø–æ—Å–ª–µ–¥–Ω—è—è M5 —Å–≤–µ—á–∞, –∫–æ—Ç–æ—Ä–∞—è –µ—Å—Ç—å –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö
    compare_time = m5_live.index[-2]  # -2 –∫–∞–∫ –≤ –ª–∞–π–≤–µ (closed candle)
    
    print(f"\nüéØ –¢–æ—á–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {compare_time}")
    
    # ========================================
    # –†–µ–∂–∏–º 1: –ü–û–õ–ù–´–ï –î–ê–ù–ù–´–ï (–∫–∞–∫ backtest)
    # ========================================
    mtf_fe = MTFFeatureEngine()
    
    print("\n‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏—á–µ–π –Ω–∞ –ü–û–õ–ù–´–• –¥–∞–Ω–Ω—ã—Ö (backtest mode)...")
    ft_full = mtf_fe.align_timeframes(m1_full, m5_full, m15_full)
    ft_full = ft_full.join(m5_full[['open', 'high', 'low', 'close', 'volume']])
    ft_full = add_volume_features(ft_full)
    ft_full = ft_full.dropna()
    
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(ft_full)} —Å—Ç—Ä–æ–∫, {len(ft_full.columns)} —Ñ–∏—á–µ–π")
    
    # ========================================
    # –†–µ–∂–∏–º 2: –¢–û–õ–¨–ö–û –ü–û–°–õ–ï–î–ù–ò–ï –°–í–ï–ß–ò (–∫–∞–∫ live)
    # ========================================
    print("\n‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏—á–µ–π –Ω–∞ –ü–û–°–õ–ï–î–ù–ò–• —Å–≤–µ—á–∞—Ö (live mode)...")
    ft_live = mtf_fe.align_timeframes(m1_live, m5_live, m15_live)
    ft_live = ft_live.join(m5_live[['open', 'high', 'low', 'close', 'volume']])
    ft_live = add_volume_features(ft_live)
    ft_live = ft_live.dropna()
    
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(ft_live)} —Å—Ç—Ä–æ–∫, {len(ft_live.columns)} —Ñ–∏—á–µ–π")
    
    # ========================================
    # –°–†–ê–í–ù–ï–ù–ò–ï –í –û–î–ù–û–ô –¢–û–ß–ö–ï
    # ========================================
    if compare_time not in ft_full.index:
        print(f"\n‚ùå –í—Ä–µ–º—è {compare_time} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ ft_full!")
        return
    if compare_time not in ft_live.index:
        print(f"\n‚ùå –í—Ä–µ–º—è {compare_time} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ ft_live!")
        return
    
    row_full = ft_full.loc[compare_time]
    row_live = ft_live.loc[compare_time]
    
    # –ù–∞—Ö–æ–¥–∏–º –æ–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    common_cols = list(set(row_full.index) & set(row_live.index))
    common_cols.sort()
    
    print(f"\n{'='*70}")
    print(f"–°–†–ê–í–ù–ï–ù–ò–ï –§–ò–ß–ï–ô –í –¢–û–ß–ö–ï {compare_time}")
    print(f"{'='*70}")
    print(f"–û–±—â–∏—Ö —Ñ–∏—á–µ–π: {len(common_cols)}")
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É
    diffs = []
    for col in common_cols:
        val_full = row_full[col]
        val_live = row_live[col]
        
        if pd.isna(val_full) or pd.isna(val_live):
            continue
        
        # Skip boolean columns
        if isinstance(val_full, (bool, np.bool_)) or isinstance(val_live, (bool, np.bool_)):
            continue
        
        # Convert to float
        val_full = float(val_full)
        val_live = float(val_live)
        
        if abs(val_full) < 1e-10 and abs(val_live) < 1e-10:
            diff = 0
        elif abs(val_full) < 1e-10:
            diff = abs(val_live)
        else:
            diff = abs(val_full - val_live) / max(abs(val_full), 1e-10)
        
        diffs.append({
            'feature': col,
            'backtest': val_full,
            'live': val_live,
            'abs_diff': abs(val_full - val_live),
            'rel_diff': diff
        })
    
    diffs_df = pd.DataFrame(diffs)
    diffs_df = diffs_df.sort_values('rel_diff', ascending=False)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–°–•–û–ñ–î–ï–ù–ò–ô:")
    print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞: {diffs_df['rel_diff'].mean()*100:.4f}%")
    print(f"   –ú–∞–∫—Å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞: {diffs_df['rel_diff'].max()*100:.4f}%")
    print(f"   –ú–µ–¥–∏–∞–Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π —Ä–∞–∑–Ω–∏—Ü—ã: {diffs_df['rel_diff'].median()*100:.4f}%")
    
    # –§–∏—á–∏ —Å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ–º > 1%
    significant = diffs_df[diffs_df['rel_diff'] > 0.01]
    print(f"\n‚ö†Ô∏è  –§–∏—á–∏ —Å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ–º > 1%: {len(significant)}")
    
    if len(significant) > 0:
        print(f"\nüî• –¢–û–ü-30 –ü–†–û–ë–õ–ï–ú–ù–´–• –§–ò–ß–ï–ô:")
        print("-" * 90)
        print(f"{'Feature':<45} {'Backtest':>12} {'Live':>12} {'Diff%':>10}")
        print("-" * 90)
        for _, row in significant.head(30).iterrows():
            print(f"{row['feature']:<45} {row['backtest']:>12.4f} {row['live']:>12.4f} {row['rel_diff']*100:>10.2f}%")
    
    # –§–∏—á–∏ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π (m5_ prefix —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã)
    m5_features = diffs_df[diffs_df['feature'].str.startswith('m5_')]
    print(f"\nüìà M5 —Ñ–∏—á–∏ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ):")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(m5_features)}")
    print(f"   –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞: {m5_features['rel_diff'].mean()*100:.4f}%")
    print(f"   –ú–∞–∫—Å —Ä–∞–∑–Ω–∏—Ü–∞: {m5_features['rel_diff'].max()*100:.4f}%")
    
    # –î—Ä—É–≥–∏–µ —Ñ–∏—á–∏
    other_features = diffs_df[~diffs_df['feature'].str.startswith('m5_')]
    print(f"\nüìà –î—Ä—É–≥–∏–µ —Ñ–∏—á–∏ (M1, M15, volume):")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(other_features)}")
    print(f"   –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞: {other_features['rel_diff'].mean()*100:.4f}%")
    print(f"   –ú–∞–∫—Å —Ä–∞–∑–Ω–∏—Ü–∞: {other_features['rel_diff'].max()*100:.4f}%")
    
    # ========================================
    # –ü–†–û–í–ï–†–Ø–ï–ú –í–õ–ò–Ø–ù–ò–ï –ù–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø
    # ========================================
    print(f"\n{'='*70}")
    print("–í–õ–ò–Ø–ù–ò–ï –ù–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print(f"{'='*70}")
    
    import joblib
    MODEL_DIR = Path(__file__).parent.parent / "models" / "v8_improved"
    
    models = {
        'direction': joblib.load(MODEL_DIR / 'direction_model.joblib'),
        'timing': joblib.load(MODEL_DIR / 'timing_model.joblib'),
        'strength': joblib.load(MODEL_DIR / 'strength_model.joblib'),
    }
    features_list = joblib.load(MODEL_DIR / 'feature_names.joblib')
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏
    def prepare_for_model(row, features_list):
        X = np.zeros(len(features_list))
        for i, f in enumerate(features_list):
            if f in row.index:
                X[i] = row[f]
            else:
                X[i] = 0.0
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        return X.reshape(1, -1)
    
    X_full = prepare_for_model(row_full, features_list)
    X_live = prepare_for_model(row_live, features_list)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    dir_proba_full = models['direction'].predict_proba(X_full)[0]
    dir_proba_live = models['direction'].predict_proba(X_live)[0]
    
    timing_full = models['timing'].predict(X_full)[0]
    timing_live = models['timing'].predict(X_live)[0]
    
    strength_full = models['strength'].predict(X_full)[0]
    strength_live = models['strength'].predict(X_live)[0]
    
    print(f"\nüìä Direction Probabilities:")
    print(f"   Backtest: SHORT={dir_proba_full[0]:.4f}, SIDEWAYS={dir_proba_full[1]:.4f}, LONG={dir_proba_full[2]:.4f}")
    print(f"   Live:     SHORT={dir_proba_live[0]:.4f}, SIDEWAYS={dir_proba_live[1]:.4f}, LONG={dir_proba_live[2]:.4f}")
    print(f"   –†–∞–∑–Ω–∏—Ü–∞ confidence: {abs(max(dir_proba_full) - max(dir_proba_live)):.4f}")
    
    print(f"\nüìä Timing:")
    print(f"   Backtest: {timing_full:.4f}")
    print(f"   Live:     {timing_live:.4f}")
    print(f"   –†–∞–∑–Ω–∏—Ü–∞: {abs(timing_full - timing_live):.4f}")
    
    print(f"\nüìä Strength:")
    print(f"   Backtest: {strength_full:.4f}")
    print(f"   Live:     {strength_live:.4f}")
    print(f"   –†–∞–∑–Ω–∏—Ü–∞: {abs(strength_full - strength_live):.4f}")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç
    print(f"\n{'='*70}")
    print("–í–ï–†–î–ò–ö–¢")
    print(f"{'='*70}")
    
    conf_diff = abs(max(dir_proba_full) - max(dir_proba_live))
    if conf_diff > 0.05:
        print(f"üî• –ö–†–ò–¢–ò–ß–ù–û! –†–∞–∑–Ω–∏—Ü–∞ –≤ confidence = {conf_diff:.4f}")
        print("   Rolling –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –í–õ–ò–Ø–ï–¢ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è!")
        print("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –æ—Ç–∫–ª—é—á–∏—Ç—å normalize=True –≤ generate_all_features()")
    else:
        print(f"‚úÖ –†–∞–∑–Ω–∏—Ü–∞ –≤ confidence = {conf_diff:.4f} (–ø—Ä–∏–µ–º–ª–µ–º–æ)")
        print("   –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏—á–∏–Ω–æ–π —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π")


if __name__ == "__main__":
    test_normalization_impact()
