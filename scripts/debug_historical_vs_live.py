#!/usr/bin/env python3
"""
–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü–æ—á–µ–º—É –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∏ live –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç–ª–∏—á–∞—é—Ç—Å—è?

–ì–∏–ø–æ—Ç–µ–∑–∞: shift(1) –¥–ª—è M15 —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ-—Ä–∞–∑–Ω–æ–º—É –¥–ª—è:
1. "–¢–µ–∫—É—â–µ–π" —Å–≤–µ—á–∏ (—Ç–æ–ª—å–∫–æ —á—Ç–æ –∑–∞–∫—Ä—ã–ª–∞—Å—å)
2. "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π" —Å–≤–µ—á–∏ (–∑–∞–∫—Ä—ã–ª–∞—Å—å –¥–∞–≤–Ω–æ)
"""
import json
import pandas as pd
import numpy as np
import joblib
import requests
from pathlib import Path
from datetime import datetime, timezone, timedelta
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from train_mtf import MTFFeatureEngine

MODEL_DIR = Path("models/v8_improved")
PAIRS_FILE = Path("config/pairs_list.json")

# Load models
models = {
    'direction': joblib.load(MODEL_DIR / 'direction_model.joblib'),
    'timing': joblib.load(MODEL_DIR / 'timing_model.joblib'),
    'strength': joblib.load(MODEL_DIR / 'strength_model.joblib'),
    'features': joblib.load(MODEL_DIR / 'feature_names.joblib')
}

mtf_fe = MTFFeatureEngine()

def fetch_klines(symbol, interval, limit=500):
    clean_symbol = symbol.replace('/USDT:USDT', 'USDT').replace('/', '')
    url = f"https://fapi.binance.com/fapi/v1/klines"
    params = {'symbol': clean_symbol, 'interval': interval, 'limit': limit}
    response = requests.get(url, params=params, timeout=30)
    data = response.json()
    
    df = pd.DataFrame(data, columns=[
        'timestamp', 'open', 'high', 'low', 'close', 'volume',
        'close_time', 'quote_volume', 'trades', 'taker_buy_base',
        'taker_buy_quote', 'ignore'
    ])
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].copy()
    for col in ['open', 'high', 'low', 'close', 'volume']:
        df[col] = df[col].astype(float)
    df.set_index('timestamp', inplace=True)
    return df

def add_volume_features(df):
    df['vol_sma_20'] = df['volume'].rolling(20).mean()
    df['vol_ratio'] = df['volume'] / df['vol_sma_20']
    df['vol_zscore'] = (df['volume'] - df['vol_sma_20']) / df['volume'].rolling(20).std()
    df['price_change'] = df['close'].diff()
    df['obv'] = np.where(df['price_change'] > 0, df['volume'], -df['volume']).cumsum()
    df['obv_sma'] = pd.Series(df['obv']).rolling(20).mean()
    df['vwap'] = (df['close'] * df['volume']).rolling(20).sum() / df['volume'].rolling(20).sum()
    df['price_vs_vwap'] = df['close'] / df['vwap'] - 1
    df['vol_momentum'] = df['volume'].pct_change(5)
    return df

def calculate_atr(df, period=14):
    high, low, close = df['high'], df['low'], df['close']
    tr = pd.concat([high - low, abs(high - close.shift()), abs(low - close.shift())], axis=1).max(axis=1)
    return tr.ewm(span=period, adjust=False).mean()

def prepare_features(m1, m5, m15):
    ft = mtf_fe.align_timeframes(m1, m5, m15)
    ft = ft.join(m5[['open', 'high', 'low', 'close', 'volume']])
    ft = add_volume_features(ft)
    ft['atr'] = calculate_atr(ft)
    ft = ft.dropna(subset=['close', 'atr']).ffill().bfill().fillna(0)
    return ft

# Load pairs
with open(PAIRS_FILE, 'r') as f:
    pairs = [p['symbol'] for p in json.load(f)['pairs'][:20]]

print("="*90)
print("üîç –ê–ù–ê–õ–ò–ó: –ö–∞–∫ M15 shift –≤–ª–∏—è–µ—Ç –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
print("="*90)

now = datetime.now(timezone.utc)
current_5m = now.replace(minute=(now.minute // 5) * 5, second=0, microsecond=0)
last_closed = current_5m - timedelta(minutes=5)

print(f"\n–¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è UTC: {now.strftime('%H:%M:%S')}")
print(f"–ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–∫—Ä—ã—Ç–∞—è M5 —Å–≤–µ—á–∞: {last_closed.strftime('%H:%M')}")

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∞—è M15 —Å–≤–µ—á–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
current_m15_start = last_closed.replace(minute=(last_closed.minute // 15) * 15)
prev_m15_start = current_m15_start - timedelta(minutes=15)

print(f"\n–î–ª—è M5 —Å–≤–µ—á–∏ {last_closed.strftime('%H:%M')}:")
print(f"   –¢–µ–∫—É—â–∞—è M15 —Å–≤–µ—á–∞: {current_m15_start.strftime('%H:%M')} (–µ—â—ë —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∏–ª–∏ —Ç–æ–ª—å–∫–æ –∑–∞–∫—Ä—ã–ª–∞—Å—å)")
print(f"   –ü–æ—Å–ª–µ shift(1): –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è M15 {prev_m15_start.strftime('%H:%M')}")

# –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä
test_pairs = ['PIPPIN/USDT:USDT', '1000PEPE/USDT:USDT', 'HYPE/USDT:USDT', 'ADA/USDT:USDT', 'TAO/USDT:USDT']

print("\n" + "="*90)
print("üìä –°–†–ê–í–ù–ï–ù–ò–ï: –ü–æ—Å–ª–µ–¥–Ω—è—è —Å–≤–µ—á–∞ (iloc[-2]) vs –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏")  
print("="*90)

for pair in test_pairs:
    print(f"\n{'='*90}")
    print(f"üìä {pair}")
    print("="*90)
    
    try:
        # Fetch data
        data = {}
        for tf in ['1m', '5m', '15m']:
            data[tf] = fetch_klines(pair, tf, 500)
        
        ft = prepare_features(data['1m'], data['5m'], data['15m'])
        
        print(f"\n   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ prepare_features: {len(ft)}")
        print(f"   –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∏–Ω–¥–µ–∫—Å–æ–≤: {[t.strftime('%H:%M') for t in ft.index[-5:]]}")
        
        # –ú–ï–¢–û–î 1: Live style - iloc[-2]
        row_live = ft.iloc[[-2]]
        live_time = row_live.index[0]
        X_live = row_live[models['features']].values
        
        dir_proba_live = models['direction'].predict_proba(X_live)
        dir_pred_live = int(np.argmax(dir_proba_live))
        dir_conf_live = float(np.max(dir_proba_live))
        timing_live = float(models['timing'].predict(X_live)[0])
        strength_live = float(models['strength'].predict(X_live)[0])
        dir_str_live = ['SHORT', 'SIDE', 'LONG'][dir_pred_live]
        
        # –ú–ï–¢–û–î 2: Backtest style - –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–≤–µ—á–µ–π
        historical_times = [ft.index[-2] - timedelta(minutes=5*i) for i in range(1, 13)]
        historical_times = [t for t in historical_times if t in ft.index]
        
        print(f"\n   {'–°–≤–µ—á–∞':<12} | {'–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ':<10} | {'Conf':<8} | {'Timing':<8} | {'Strength':<8} | Close")
        print(f"   {'-'*80}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é (live style)
        close_live = row_live['close'].values[0]
        print(f"   {live_time.strftime('%H:%M'):<12} | {dir_str_live:<10} | {dir_conf_live:<8.3f} | {timing_live:<8.2f} | {strength_live:<8.2f} | {close_live:.6f} ‚Üê iloc[-2]")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ
        for hist_time in historical_times[:8]:
            row_hist = ft.loc[[hist_time]]
            X_hist = row_hist[models['features']].values
            
            dir_proba_hist = models['direction'].predict_proba(X_hist)
            dir_pred_hist = int(np.argmax(dir_proba_hist))
            dir_conf_hist = float(np.max(dir_proba_hist))
            timing_hist = float(models['timing'].predict(X_hist)[0])
            strength_hist = float(models['strength'].predict(X_hist)[0])
            dir_str_hist = ['SHORT', 'SIDE', 'LONG'][dir_pred_hist]
            close_hist = row_hist['close'].values[0]
            
            # –û—Ç–º–µ—á–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—Ö–æ–¥—è—Ç —Ñ–∏–ª—å—Ç—Ä—ã
            passes_filters = dir_pred_hist != 1 and dir_conf_hist >= 0.50 and timing_hist >= 0.8 and strength_hist >= 1.4
            marker = "‚úÖ SIGNAL" if passes_filters else ""
            
            print(f"   {hist_time.strftime('%H:%M'):<12} | {dir_str_hist:<10} | {dir_conf_hist:<8.3f} | {timing_hist:<8.2f} | {strength_hist:<8.2f} | {close_hist:.6f} {marker}")
        
    except Exception as e:
        print(f"   ERROR: {e}")

print("\n" + "="*90)
print("üí° –í–´–í–û–î:")
print("   –ï—Å–ª–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–µ–Ω—è—é—Ç—Å—è –æ—Ç —Å–≤–µ—á–∏ –∫ —Å–≤–µ—á–µ - —ç—Ç–æ –ù–û–†–ú–ê–õ–¨–ù–û (—Ä—ã–Ω–æ–∫ –º–µ–Ω—è–µ—Ç—Å—è)")
print("   –ü—Ä–æ–±–ª–µ–º–∞ –µ—Å–ª–∏ iloc[-2] –∏ ft.loc[same_time] –¥–∞—é—Ç –†–ê–ó–ù–´–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
print("="*90)

# –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: iloc[-2] vs loc[same_timestamp]
print("\n" + "="*90)
print("üîç –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: iloc[-2] vs loc[same_time]")
print("="*90)

for pair in test_pairs[:3]:
    print(f"\n{pair}:")
    data = {}
    for tf in ['1m', '5m', '15m']:
        data[tf] = fetch_klines(pair, tf, 500)
    ft = prepare_features(data['1m'], data['5m'], data['15m'])
    
    # iloc[-2]
    row_iloc = ft.iloc[[-2]]
    time_iloc = row_iloc.index[0]
    
    # loc[same_time]
    row_loc = ft.loc[[time_iloc]]
    
    # Compare
    X_iloc = row_iloc[models['features']].values
    X_loc = row_loc[models['features']].values
    
    features_match = np.allclose(X_iloc, X_loc, equal_nan=True)
    
    pred_iloc = models['direction'].predict_proba(X_iloc)
    pred_loc = models['direction'].predict_proba(X_loc)
    
    preds_match = np.allclose(pred_iloc, pred_loc)
    
    print(f"   Time: {time_iloc.strftime('%H:%M')}")
    print(f"   Features match: {'‚úÖ' if features_match else '‚ùå'}")
    print(f"   Predictions match: {'‚úÖ' if preds_match else '‚ùå'}")
    
    if not features_match:
        diff_count = np.sum(~np.isclose(X_iloc, X_loc, equal_nan=True))
        print(f"   ‚ö†Ô∏è {diff_count} features differ!")

