#!/usr/bin/env python3
"""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –±–µ–∫—Ç–µ—Å—Ç–µ vs –ª–∞–π–≤–µ
–ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–∞–ª—å–Ω—É—é –ø—Ä–∏—á–∏–Ω—É —Ä–∞–∑–ª–∏—á–∏–π –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö
"""

import sys
import pandas as pd
import numpy as np
import joblib
import ccxt
from pathlib import Path
from datetime import datetime, timedelta, timezone
from loguru import logger

sys.path.insert(0, str(Path(__file__).parent.parent))
from train_mtf import MTFFeatureEngine

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ train_v3_dynamic
import importlib.util
spec = importlib.util.spec_from_file_location("train_v3_dynamic", Path(__file__).parent / "train_v3_dynamic.py")
train_v3 = importlib.util.module_from_spec(spec)
spec.loader.exec_module(train_v3)
add_volume_features = train_v3.add_volume_features
calculate_atr = train_v3.calculate_atr

# Config
MODEL_DIR = Path("models/v8_improved")
PAIRS_FILE = Path("config/pairs_list.json")
DATA_DIR = Path("data/candles")
TIMEFRAMES = ['1m', '5m', '15m']
LOOKBACK = 1500

# Thresholds
MIN_CONF = 0.50
MIN_TIMING = 0.8
MIN_STRENGTH = 1.4


def load_models():
    """Load trained models"""
    models = {
        'direction': joblib.load(MODEL_DIR / 'direction_model.joblib'),
        'timing': joblib.load(MODEL_DIR / 'timing_model.joblib'),
        'strength': joblib.load(MODEL_DIR / 'strength_model.joblib'),
        'features': joblib.load(MODEL_DIR / 'feature_names.joblib')
    }
    logger.info(f"‚úÖ Loaded models: {len(models['features'])} features")
    return models


def prepare_features_backtest(m1, m5, m15, mtf_fe):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π –ö–ê–ö –í –ë–ï–ö–¢–ï–°–¢–ï (–∏–∑ train_v3_dynamic.py)"""
    # –¢–æ—á–Ω–æ –∫–∞–∫ –≤ train_v3_dynamic.py —Å—Ç—Ä–æ–∫–∞ 724-726
    ft = mtf_fe.align_timeframes(m1, m5, m15)
    ft = ft.join(m5[['open', 'high', 'low', 'close', 'volume']])
    ft = add_volume_features(ft)
    ft['atr'] = calculate_atr(ft)
    return ft


def prepare_features_live(data, mtf_fe):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π –ö–ê–ö –ù–ê –õ–ê–ô–í–ï (–∏–∑ live_trading_mexc_v8.py)"""
    m1 = data['1m']
    m5 = data['5m']
    m15 = data['15m']
    
    if len(m1) < 50 or len(m5) < 50 or len(m15) < 50:
        return pd.DataFrame()
    
    # Ensure DatetimeIndex
    for df in [m1, m5, m15]:
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index, utc=True)
        df.sort_index(inplace=True)
    
    try:
        ft = mtf_fe.align_timeframes(m1, m5, m15)
        if len(ft) == 0:
            return pd.DataFrame()
        
        ft = ft.join(m5[['open', 'high', 'low', 'close', 'volume']])
        ft = add_volume_features(ft)
        ft['atr'] = calculate_atr(ft)
        
        # Fill NaN (–∫–∞–∫ –Ω–∞ –ª–∞–π–≤–µ)
        critical_cols = ['close', 'atr']
        ft = ft.dropna(subset=critical_cols)
        ft = ft.ffill().bfill()
        
        if ft.isna().any().any():
            ft = ft.fillna(0)
        
        return ft
    except Exception as e:
        logger.error(f"Error: {e}")
        return pd.DataFrame()


def compare_features(ft_backtest, ft_live, feature_names, timestamp):
    """–°—Ä–∞–≤–Ω–∏—Ç—å —Ñ–∏—á–∏ –º–µ–∂–¥—É –±–µ–∫—Ç–µ—Å—Ç–æ–º –∏ –ª–∞–π–≤–æ–º"""
    logger.info(f"\n{'='*70}")
    logger.info(f"üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∏—á–µ–π –¥–ª—è timestamp: {timestamp}")
    logger.info(f"{'='*70}")
    
    # –ù–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫—É –≤ –±–µ–∫—Ç–µ—Å—Ç–µ
    if timestamp not in ft_backtest.index:
        logger.warning(f"Timestamp {timestamp} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–µ–∫—Ç–µ—Å—Ç–µ!")
        return None
    
    row_backtest = ft_backtest.loc[[timestamp]]
    row_live = ft_live.loc[[timestamp]]
    
    if len(row_live) == 0:
        logger.warning(f"Timestamp {timestamp} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –ª–∞–π–≤–µ!")
        return None
    
    # –°—Ä–∞–≤–Ω–∏—Ç—å –∫–∞–∂–¥—É—é —Ñ–∏—á—É
    differences = []
    missing_in_live = []
    missing_in_backtest = []
    
    for feat in feature_names:
        if feat not in row_backtest.columns:
            missing_in_backtest.append(feat)
            continue
        
        if feat not in row_live.columns:
            missing_in_live.append(feat)
            continue
        
        val_backtest = row_backtest[feat].iloc[0]
        val_live = row_live[feat].iloc[0]
        
        if pd.isna(val_backtest) or pd.isna(val_live):
            if pd.isna(val_backtest) != pd.isna(val_live):
                differences.append({
                    'feature': feat,
                    'backtest': val_backtest,
                    'live': val_live,
                    'diff': 'NaN mismatch'
                })
            continue
        
        # –°—Ä–∞–≤–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è
        if isinstance(val_backtest, (int, float)) and isinstance(val_live, (int, float)):
            diff_pct = abs(val_backtest - val_live) / (abs(val_backtest) + 1e-10) * 100
            if diff_pct > 0.1 or abs(val_backtest - val_live) > 1e-6:  # –†–∞–∑–Ω–∏—Ü–∞ > 0.1% –∏–ª–∏ > 1e-6
                differences.append({
                    'feature': feat,
                    'backtest': val_backtest,
                    'live': val_live,
                    'diff_pct': diff_pct,
                    'diff_abs': abs(val_backtest - val_live)
                })
        elif val_backtest != val_live:
            differences.append({
                'feature': feat,
                'backtest': val_backtest,
                'live': val_live,
                'diff': 'value mismatch'
            })
    
    # –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if missing_in_backtest:
        logger.warning(f"‚ö†Ô∏è  –§–∏—á–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –±–µ–∫—Ç–µ—Å—Ç–µ: {missing_in_backtest[:10]}")
    
    if missing_in_live:
        logger.error(f"‚ùå –§–∏—á–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–∞ –ª–∞–π–≤–µ: {missing_in_live[:10]}")
        return None
    
    if differences:
        logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(differences)} —Ä–∞–∑–ª–∏—á–∏–π –≤ —Ñ–∏—á–∞—Ö!")
        logger.info(f"\n–¢–æ–ø-20 –Ω–∞–∏–±–æ–ª—å—à–∏—Ö —Ä–∞–∑–ª–∏—á–∏–π:")
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–π —Ä–∞–∑–Ω–∏—Ü–µ
        sorted_diffs = sorted(differences, key=lambda x: x.get('diff_abs', 0) or x.get('diff_pct', 0), reverse=True)
        
        for i, diff in enumerate(sorted_diffs[:20], 1):
            if 'diff_pct' in diff:
                logger.info(f"  {i}. {diff['feature']}: "
                          f"backtest={diff['backtest']:.6f}, "
                          f"live={diff['live']:.6f}, "
                          f"diff={diff['diff_pct']:.2f}%")
            else:
                logger.info(f"  {i}. {diff['feature']}: "
                          f"backtest={diff['backtest']}, "
                          f"live={diff['live']}, "
                          f"diff={diff.get('diff', 'N/A')}")
        
        return sorted_diffs
    else:
        logger.info("‚úÖ –í—Å–µ —Ñ–∏—á–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç!")
        return []


def compare_predictions(ft_backtest, ft_live, models, timestamp):
    """–°—Ä–∞–≤–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    logger.info(f"\n{'='*70}")
    logger.info(f"üéØ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è timestamp: {timestamp}")
    logger.info(f"{'='*70}")
    
    # –ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–æ–∫–∏
    if timestamp not in ft_backtest.index:
        return None
    
    row_backtest = ft_backtest.loc[[timestamp]]
    row_live = ft_live.loc[[timestamp]]
    
    if len(row_live) == 0:
        return None
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ñ–∏—á–µ–π
    missing_backtest = [f for f in models['features'] if f not in row_backtest.columns]
    missing_live = [f for f in models['features'] if f not in row_live.columns]
    
    if missing_backtest:
        logger.warning(f"‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏—á–∏ –≤ –±–µ–∫—Ç–µ—Å—Ç–µ: {missing_backtest[:5]}")
        # –î–æ–±–∞–≤–∏—Ç—å –Ω—É–ª–∏
        for f in missing_backtest:
            row_backtest[f] = 0
    
    if missing_live:
        logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏—á–∏ –Ω–∞ –ª–∞–π–≤–µ: {missing_live[:5]}")
        return None
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –±–µ–∫—Ç–µ—Å—Ç–µ
    X_backtest = row_backtest[models['features']].values
    if pd.isna(X_backtest).any():
        logger.warning("‚ö†Ô∏è  NaN –≤ —Ñ–∏—á–∞—Ö –±–µ–∫—Ç–µ—Å—Ç–∞!")
        X_backtest = np.nan_to_num(X_backtest, nan=0.0)
    
    dir_proba_backtest = models['direction'].predict_proba(X_backtest)
    dir_conf_backtest = float(np.max(dir_proba_backtest))
    dir_pred_backtest = int(np.argmax(dir_proba_backtest))
    timing_backtest = float(models['timing'].predict(X_backtest)[0])
    strength_backtest = float(models['strength'].predict(X_backtest)[0])
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –ª–∞–π–≤–µ
    X_live = row_live[models['features']].values
    if pd.isna(X_live).any():
        logger.warning("‚ö†Ô∏è  NaN –≤ —Ñ–∏—á–∞—Ö –ª–∞–π–≤–∞!")
        X_live = np.nan_to_num(X_live, nan=0.0)
    
    dir_proba_live = models['direction'].predict_proba(X_live)
    dir_conf_live = float(np.max(dir_proba_live))
    dir_pred_live = int(np.argmax(dir_proba_live))
    timing_live = float(models['timing'].predict(X_live)[0])
    strength_live = float(models['strength'].predict(X_live)[0])
    
    # –í—ã–≤–µ—Å—Ç–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    logger.info(f"\nüìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    logger.info(f"  Direction: backtest={dir_pred_backtest} (conf={dir_conf_backtest:.3f}), "
              f"live={dir_pred_live} (conf={dir_conf_live:.3f}), "
              f"diff={abs(dir_conf_backtest - dir_conf_live):.3f}")
    logger.info(f"  Timing: backtest={timing_backtest:.3f}, live={timing_live:.3f}, "
              f"diff={abs(timing_backtest - timing_live):.3f}")
    logger.info(f"  Strength: backtest={strength_backtest:.3f}, live={strength_live:.3f}, "
              f"diff={abs(strength_backtest - strength_live):.3f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –ø—Ä–æ—Ö–æ–¥—è—Ç –ª–∏ —Ñ–∏–ª—å—Ç—Ä—ã
    def check_filters(conf, timing, strength, pred):
        passed = []
        if pred == 1:
            return False, ["SIDEWAYS"]
        if conf < MIN_CONF:
            passed.append(f"Conf({conf:.2f}<{MIN_CONF})")
        if timing < MIN_TIMING:
            passed.append(f"Timing({timing:.2f}<{MIN_TIMING})")
        if strength < MIN_STRENGTH:
            passed.append(f"Strength({strength:.1f}<{MIN_STRENGTH})")
        return len(passed) == 0, passed
    
    backtest_passed, backtest_reasons = check_filters(dir_conf_backtest, timing_backtest, strength_backtest, dir_pred_backtest)
    live_passed, live_reasons = check_filters(dir_conf_live, timing_live, strength_live, dir_pred_live)
    
    logger.info(f"\n‚úÖ –§–∏–ª—å—Ç—Ä—ã:")
    logger.info(f"  Backtest: {'‚úÖ PASSED' if backtest_passed else '‚ùå REJECTED'} {backtest_reasons}")
    logger.info(f"  Live: {'‚úÖ PASSED' if live_passed else '‚ùå REJECTED'} {live_reasons}")
    
    return {
        'backtest': {
            'conf': dir_conf_backtest,
            'timing': timing_backtest,
            'strength': strength_backtest,
            'pred': dir_pred_backtest,
            'passed': backtest_passed
        },
        'live': {
            'conf': dir_conf_live,
            'timing': timing_live,
            'strength': strength_live,
            'pred': dir_pred_live,
            'passed': live_passed
        }
    }


def main():
    import json
    
    logger.info("=" * 70)
    logger.info("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–µ–∫—Ç–µ—Å—Ç–∞ –∏ –ª–∞–π–≤–∞ - –ø–æ–∏—Å–∫ –ø—Ä–∏—á–∏–Ω—ã —Ä–∞–∑–ª–∏—á–∏–π")
    logger.info("=" * 70)
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏
    models = load_models()
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ä—ã
    with open(PAIRS_FILE) as f:
        pairs_data = json.load(f)
    pairs = [p['symbol'] for p in pairs_data['pairs'][:3]]  # –¢–µ—Å—Ç–∏—Ä—É–µ–º 3 –ø–∞—Ä—ã
    
    mtf_fe = MTFFeatureEngine()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Binance
    binance = ccxt.binance({
        'timeout': 10000,
        'enableRateLimit': True,
        'options': {'defaultType': 'future'}
    })
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥ –∏–∑ CSV (–±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å –≤ CSV
    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ CSV...")
    
    # –ù–∞–π–¥–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–æ—Å—Ç—É–ø–Ω—É—é –¥–∞—Ç—É –≤ CSV
    test_pair_name = pairs[0].replace('/', '_').replace(':', '_')
    try:
        m5_test = pd.read_csv(DATA_DIR / f"{test_pair_name}_5m.csv", 
                             parse_dates=['timestamp'], index_col='timestamp')
        if m5_test.index.tz is None:
            m5_test.index = m5_test.index.tz_localize('UTC')
        
        if len(m5_test) > 0:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è –∏–∑ CSV
            end_date = m5_test.index.max()
            start_date = end_date - timedelta(days=3)
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥ –∏–∑ CSV: {start_date.date()} - {end_date.date()}")
        else:
            # Fallback: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
            end_date = datetime.now(timezone.utc)
            start_date = end_date - timedelta(days=7)
            logger.info(f"CSV –ø—É—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π: {start_date.date()} - {end_date.date()}")
    except FileNotFoundError:
        # Fallback: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        end_date = datetime.now(timezone.utc)
        start_date = end_date - timedelta(days=7)
        logger.info(f"CSV –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π: {start_date.date()} - {end_date.date()}")
    
    for pair in pairs:
        logger.info(f"\n{'='*70}")
        logger.info(f"–ü–∞—Ä–∞: {pair}")
        logger.info(f"{'='*70}")
        
        pair_name = pair.replace('/', '_').replace(':', '_')
        
        try:
            # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV (–∫–∞–∫ –≤ –±–µ–∫—Ç–µ—Å—Ç–µ)
            logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV (–±–µ–∫—Ç–µ—Å—Ç)...")
            try:
                m1_backtest = pd.read_csv(DATA_DIR / f"{pair_name}_1m.csv", 
                                         parse_dates=['timestamp'], index_col='timestamp')
                m5_backtest = pd.read_csv(DATA_DIR / f"{pair_name}_5m.csv", 
                                         parse_dates=['timestamp'], index_col='timestamp')
                m15_backtest = pd.read_csv(DATA_DIR / f"{pair_name}_15m.csv", 
                                          parse_dates=['timestamp'], index_col='timestamp')
                
                # –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∏–Ω–¥–µ–∫—Å—ã –∏–º–µ—é—Ç timezone (–µ—Å–ª–∏ CSV –±–µ–∑ timezone, –¥–æ–±–∞–≤–∏—Ç—å UTC)
                if m1_backtest.index.tz is None:
                    m1_backtest.index = m1_backtest.index.tz_localize('UTC')
                if m5_backtest.index.tz is None:
                    m5_backtest.index = m5_backtest.index.tz_localize('UTC')
                if m15_backtest.index.tz is None:
                    m15_backtest.index = m15_backtest.index.tz_localize('UTC')
                
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV (–Ω–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ –¥–∞—Ç–∞–º)
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–≤–µ—á–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å
                if len(m5_backtest) < 200:
                    logger.warning(f"–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –≤ CSV –¥–ª—è {pair} (—Ç–æ–ª—å–∫–æ {len(m5_backtest)} —Å–≤–µ—á–µ–π)")
                    if len(m5_backtest) < 50:
                        continue
                
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–≤–µ—á–µ–π –∏–∑ CSV –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                m5_backtest = m5_backtest.tail(200)
                # –ù–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è m1 –∏ m15
                m5_start = m5_backtest.index[0]
                m5_end = m5_backtest.index[-1]
                m1_backtest = m1_backtest[(m1_backtest.index >= m5_start) & (m1_backtest.index <= m5_end)]
                m15_backtest = m15_backtest[(m15_backtest.index >= m5_start) & (m15_backtest.index <= m5_end)]
                
                # –û–±–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–∏–æ–¥ –¥–ª—è API –∑–∞–ø—Ä–æ—Å–∞
                actual_start = m5_backtest.index[0]
                actual_end = m5_backtest.index[-1]
                logger.info(f"  –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥ –∏–∑ CSV: {actual_start} - {actual_end}")
                
                logger.info(f"  CSV: M1={len(m1_backtest)}, M5={len(m5_backtest)}, M15={len(m15_backtest)}")
                
            except FileNotFoundError:
                logger.warning(f"CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {pair}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API (–∫–∞–∫ –Ω–∞ –ª–∞–π–≤–µ) –∑–∞ —Ç–æ—Ç –∂–µ –ø–µ—Ä–∏–æ–¥
            logger.info("üåê –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ API (–ª–∞–π–≤)...")
            data_live = {}
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥ –∏–∑ CSV
            actual_start = m5_backtest.index[0]
            actual_end = m5_backtest.index[-1]
            
            for tf in TIMEFRAMES:
                # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –ø–æ–∫—Ä—ã—Ç—å –ø–µ—Ä–∏–æ–¥
                since = int((actual_start - timedelta(days=1)).timestamp() * 1000)
                candles = binance.fetch_ohlcv(pair, tf, since=since, limit=LOOKBACK)
                if not candles or len(candles) < 50:
                    logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö {tf} –¥–ª—è {pair}")
                    break
                
                df = pd.DataFrame(candles, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
                df.set_index('timestamp', inplace=True)
                
                # –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ –ø–µ—Ä–∏–æ–¥—É –∏–∑ CSV
                df = df[(df.index >= actual_start) & (df.index <= actual_end)]
                data_live[tf] = df
            
            if len(data_live) < 3:
                continue
            
            logger.info(f"  API: M1={len(data_live['1m'])}, M5={len(data_live['5m'])}, M15={len(data_live['15m'])}")
            
            # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ñ–∏—á–∏ (–±–µ–∫—Ç–µ—Å—Ç)
            logger.info("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π (–±–µ–∫—Ç–µ—Å—Ç)...")
            ft_backtest = prepare_features_backtest(m1_backtest, m5_backtest, m15_backtest, mtf_fe)
            logger.info(f"  –§–∏—á–∏ –±–µ–∫—Ç–µ—Å—Ç–∞: {len(ft_backtest)} —Å—Ç—Ä–æ–∫, {len(ft_backtest.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            
            # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ñ–∏—á–∏ (–ª–∞–π–≤)
            logger.info("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π (–ª–∞–π–≤)...")
            ft_live = prepare_features_live(data_live, mtf_fe)
            logger.info(f"  –§–∏—á–∏ –ª–∞–π–≤–∞: {len(ft_live)} —Å—Ç—Ä–æ–∫, {len(ft_live.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            
            if len(ft_backtest) == 0 or len(ft_live) == 0:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ñ–∏—á–∏")
                continue
            
            # 5. –ù–∞–π—Ç–∏ –æ–±—â–∏–µ timestamps
            common_timestamps = ft_backtest.index.intersection(ft_live.index)
            if len(common_timestamps) == 0:
                logger.warning("–ù–µ—Ç –æ–±—â–∏—Ö timestamps!")
                continue
            
            logger.info(f"  –û–±—â–∏—Ö timestamps: {len(common_timestamps)}")
            
            # 6. –°—Ä–∞–≤–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–≤–µ—á–µ–π
            test_timestamps = common_timestamps[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–≤–µ—á–µ–π
            
            for ts in test_timestamps:
                # –°—Ä–∞–≤–Ω–∏—Ç—å —Ñ–∏—á–∏
                diff_features = compare_features(ft_backtest, ft_live, models['features'], ts)
                
                # –°—Ä–∞–≤–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                pred_comparison = compare_predictions(ft_backtest, ft_live, models, ts)
                
                if pred_comparison and not pred_comparison['backtest']['passed'] and pred_comparison['live']['passed']:
                    logger.error(f"üö® –ù–ê–ô–î–ï–ù–ê –ü–†–û–ë–õ–ï–ú–ê! –ù–∞ {ts} –±–µ–∫—Ç–µ—Å—Ç –æ—Ç–∫–ª–æ–Ω—è–µ—Ç, –∞ –ª–∞–π–≤ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç!")
                elif pred_comparison and pred_comparison['backtest']['passed'] and not pred_comparison['live']['passed']:
                    logger.error(f"üö® –ù–ê–ô–î–ï–ù–ê –ü–†–û–ë–õ–ï–ú–ê! –ù–∞ {ts} –±–µ–∫—Ç–µ—Å—Ç –ø—Ä–∏–Ω–∏–º–∞–µ—Ç, –∞ –ª–∞–π–≤ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç!")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {pair}: {e}")
            import traceback
            traceback.print_exc()
            continue


if __name__ == '__main__':
    main()

