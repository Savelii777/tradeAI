#!/usr/bin/env python3
"""
–ü–æ–∏—Å–∫ –º–æ–º–µ–Ω—Ç–æ–≤ –∫–æ–≥–¥–∞ –±—ã–ª–∏ —Ä–µ–∞–ª—å–Ω—ã–µ LONG/SHORT —Å–∏–≥–Ω–∞–ª—ã —Å –≤—ã—Å–æ–∫–∏–º confidence
"""

import sys
import pandas as pd
import numpy as np
import joblib
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent))

from train_mtf import MTFFeatureEngine

DATA_DIR = Path(__file__).parent.parent / "data" / "candles"
MODEL_DIR = Path(__file__).parent.parent / "models" / "v8_improved"


def add_volume_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df['vol_sma_20'] = df['volume'].rolling(20).mean()
    df['vol_ratio'] = df['volume'] / df['vol_sma_20']
    df['vol_zscore'] = (df['volume'] - df['vol_sma_20']) / df['volume'].rolling(20).std()
    df['vwap'] = (df['close'] * df['volume']).rolling(20).sum() / df['volume'].rolling(20).sum()
    df['price_vs_vwap'] = df['close'] / df['vwap'] - 1
    df['vol_momentum'] = df['volume'].pct_change(5)
    return df


def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    high = df['high']
    low = df['low']
    close = df['close']
    tr = pd.concat([
        high - low,
        abs(high - close.shift()),
        abs(low - close.shift())
    ], axis=1).max(axis=1)
    return tr.ewm(span=period, adjust=False).mean()


def find_good_signals():
    print("=" * 80)
    print("–ü–û–ò–°–ö –•–û–†–û–®–ò–• –°–ò–ì–ù–ê–õ–û–í –í –ò–°–¢–û–†–ò–ò")
    print("=" * 80)
    
    # Load models
    models = {
        'direction': joblib.load(MODEL_DIR / 'direction_model.joblib'),
        'timing': joblib.load(MODEL_DIR / 'timing_model.joblib'),
        'strength': joblib.load(MODEL_DIR / 'strength_model.joblib'),
    }
    features_list = joblib.load(MODEL_DIR / 'feature_names.joblib')
    
    mtf_fe = MTFFeatureEngine()
    
    pair = "BTC/USDT:USDT"
    pair_name = pair.replace('/', '_').replace(':', '_')
    
    # Load full data
    m1 = pd.read_csv(DATA_DIR / f"{pair_name}_1m.csv", parse_dates=['timestamp'], index_col='timestamp')
    m5 = pd.read_csv(DATA_DIR / f"{pair_name}_5m.csv", parse_dates=['timestamp'], index_col='timestamp')
    m15 = pd.read_csv(DATA_DIR / f"{pair_name}_15m.csv", parse_dates=['timestamp'], index_col='timestamp')
    
    print(f"\nüìä –î–∞–Ω–Ω—ã–µ: {m5.index[0]} ‚Üí {m5.index[-1]}")
    
    # Generate features for ALL data
    print("\n‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏—á–µ–π –¥–ª—è –≤—Å–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞...")
    ft = mtf_fe.align_timeframes(m1, m5, m15)
    ft = ft.join(m5[['open', 'high', 'low', 'close', 'volume']])
    ft = add_volume_features(ft)
    ft['atr'] = calculate_atr(ft)
    ft = ft.dropna()
    
    print(f"   –í—Å–µ–≥–æ —Å–≤–µ—á–µ–π —Å —Ñ–∏—á–∞–º–∏: {len(ft)}")
    
    # Predict for ALL rows
    print("\n‚è≥ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö —Å–≤–µ—á–µ–π...")
    
    # Prepare features matrix
    X = np.zeros((len(ft), len(features_list)))
    for i, f in enumerate(features_list):
        if f in ft.columns:
            X[:, i] = ft[f].values
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
    
    # Predict
    dir_proba = models['direction'].predict_proba(X)
    timing = models['timing'].predict(X)
    strength = models['strength'].predict(X)
    
    dir_pred = np.argmax(dir_proba, axis=1)
    dir_conf = np.max(dir_proba, axis=1)
    
    # Add to dataframe
    ft['direction'] = dir_pred  # 0=SHORT, 1=SIDEWAYS, 2=LONG
    ft['conf'] = dir_conf
    ft['timing'] = timing
    ft['strength'] = strength
    
    # Filter for good signals
    good_signals = ft[
        (ft['direction'] != 1) &  # Not SIDEWAYS
        (ft['conf'] >= 0.50) &
        (ft['timing'] >= 0.8) &
        (ft['strength'] >= 1.4)
    ]
    
    print(f"\nüéØ –•–û–†–û–®–ò–ï –°–ò–ì–ù–ê–õ–´ (CONF>=0.50, T>=0.8, S>=1.4):")
    print(f"   –í—Å–µ–≥–æ: {len(good_signals)} –∏–∑ {len(ft)} ({100*len(good_signals)/len(ft):.2f}%)")
    
    # Split by direction
    longs = good_signals[good_signals['direction'] == 2]
    shorts = good_signals[good_signals['direction'] == 0]
    
    print(f"   LONG: {len(longs)}")
    print(f"   SHORT: {len(shorts)}")
    
    # Show distribution by date
    print("\nüìÖ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –î–ù–Ø–ú:")
    good_signals_daily = good_signals.groupby(good_signals.index.date).size()
    
    print(f"   –î–Ω–µ–π —Å —Å–∏–≥–Ω–∞–ª–∞–º–∏: {len(good_signals_daily)}")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ —Å–∏–≥–Ω–∞–ª–æ–≤/–¥–µ–Ω—å: {good_signals_daily.mean():.1f}")
    
    # Show last 30 days
    print("\nüìÖ –ü–û–°–õ–ï–î–ù–ò–ï 30 –î–ù–ï–ô:")
    last_30_days = good_signals_daily.tail(30)
    for date, count in last_30_days.items():
        day_signals = good_signals[good_signals.index.date == date]
        long_count = len(day_signals[day_signals['direction'] == 2])
        short_count = len(day_signals[day_signals['direction'] == 0])
        print(f"   {date}: {count:3d} —Å–∏–≥–Ω–∞–ª–æ–≤ (L:{long_count:2d}, S:{short_count:2d})")
    
    # When was the last good signal?
    if len(good_signals) > 0:
        print(f"\n‚è∞ –ü–û–°–õ–ï–î–ù–ò–ô –•–û–†–û–®–ò–ô –°–ò–ì–ù–ê–õ:")
        last_sig = good_signals.iloc[-1]
        direction = ['SHORT', 'SIDEWAYS', 'LONG'][int(last_sig['direction'])]
        print(f"   –í—Ä–µ–º—è: {good_signals.index[-1]}")
        print(f"   –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction}")
        print(f"   Confidence: {last_sig['conf']:.3f}")
        print(f"   Timing: {last_sig['timing']:.2f}")
        print(f"   Strength: {last_sig['strength']:.2f}")
    
    # What's the current state?
    print(f"\nüìä –¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï (–ø–æ—Å–ª–µ–¥–Ω—è—è —Å–≤–µ—á–∞):")
    last = ft.iloc[-1]
    direction = ['SHORT', 'SIDEWAYS', 'LONG'][int(last['direction'])]
    print(f"   –í—Ä–µ–º—è: {ft.index[-1]}")
    print(f"   –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction}")
    print(f"   Confidence: {last['conf']:.3f}")
    print(f"   Timing: {last['timing']:.2f}")
    print(f"   Strength: {last['strength']:.2f}")
    
    # Distribution of directions
    print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–ô (–≤–µ—Å—å –ø–µ—Ä–∏–æ–¥):")
    dir_counts = ft['direction'].value_counts()
    total = len(ft)
    for d, count in sorted(dir_counts.items()):
        name = ['SHORT', 'SIDEWAYS', 'LONG'][d]
        print(f"   {name}: {count} ({100*count/total:.1f}%)")


if __name__ == "__main__":
    find_good_signals()
